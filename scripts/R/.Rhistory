cells_body(
columns = everything(),
rows = Metric == metric7
)
)
your_table <- your_table %>%
tab_header(
title = md("Dementia Screening with JORM and IADL"),
subtitle = md("All participants had imputed data with HMSE")
)
}
# Add footnote stating the comparison outcome
if(params$mci==FALSE) {
your_table <- your_table %>%
# Comparison outcome is Dementia (> 0.5 on the CDR)
tab_footnote(
footnote = md("Comparison Outcome is Clinical Dementia Rating where > 0.5 signifies dementia")
) %>%
# Add footnote defining Youden's Index
tab_footnote(
footnote = md("Youden's Index = Sensitivity + Specificity - 1. Higher is better")
) %>%
# Add footnote defining distance metric
tab_footnote(
footnote = md("Distance = distance from upper left corner or perfect discrimination. Lower is better")
)
} else {
# Add footnote for when comparion is mild cognitive impairment
your_table <- your_table %>%
tab_footnote(
footnote = md("Comparison Outcome in Clinical Dementia Rating of Mild Cognitive Impairment (0.5)")
)
}
if(params$edu_low==TRUE) {
your_table <- your_table %>%
tab_footnote(
footnote = md("All participants < 6 years education")
)
} else {}
# The below code adds footnotes if sub-demographics of the population were assessed (e.g, participants with >= 6 years of education)
if(params$edu_high==TRUE) {
your_table <- your_table %>%
tab_footnote(
footnote = md("All participants >= 6 years education")
)
} else {}
if (params$rural) {your_table <- your_table %>%
tab_footnote(
footnote = md("All participants from rural communities")
)
} else {}
if (params$urban) {your_table <- your_table %>%
tab_footnote(
footnote = md("All participants from urban communities")
)
} else {}
if (params$illiterate) {your_table <- your_table %>%
tab_footnote(
footnote = md("All participants can not read or write")
)
} else {}
if (params$literate) {your_table <- your_table %>%
tab_footnote(
footnote = md("All participants can read or write")
)
} else {}
if (params$gender == "male"){
your_table <- your_table %>%
tab_footnote(
footnote = md("Only Males")
)
} else if (params$gender == "female") {
your_table <- your_table %>%
tab_footnote(
footnote = md("Only Females")
)
} else if (params$gender == "ignore") {}
# Add color to better scoring values to more easily identify top performers
your_table <- your_table %>%
data_color(
columns = everything(),
# Color the metrics where higher scores indicate better performance
rows = Metric %in% c(
"Accuracy",
"Sensitivity",
"Specificity",
"AUC",
"Matthew_Class_Correlation",
"Youdens_Index"
),
method = "numeric",
domain = c(0.85, 1.0),
palette = "GnBu",
na_color = "lightgrey"
) %>%
# Color the metrics where lower scores indicate better performance, those this is not consistently reflected in the table output
data_color(
columns = everything(),
rows = Metric %in% c(
"Distance"
),
method = "numeric",
domain = c(0.0, 0.25),
palette = "GnBu",
na_color = "lightgrey",
reverse = TRUE
)
# Print the table
your_table
if(params$one_var==TRUE) {
# Define the cutoff of the variable of interest. Uncomment the variable of interest and ensure the other is commented out
# JORM one var cutoff
one_var_cutoff <- seq(3, 5, 0.1)
# HMSE one var cutoff
#one_var_cutoff <- seq(20, 30, 1)
# Define tests and gold standards strings for data manipulation
test_1 <- as.character("jorm")
test_2 <- as.character("hmse")
# Define the outcomes (cdr is positive for participants with a score of > 0.5 on the CDR, cdr_mci is positive for participants with a score of 0.5 on the CDR)
screen_dataset3 <- screen_dataset %>%
dplyr::select(c(
prim_key,
screen_flag,
r1cdr_final,
r1jormscore,
r1hmse_score,
r1iadltot1_d,
r1bl1score,
r1act_trav,
blover
)) %>%
mutate(cdr =
case_when(
r1cdr_final == 0 ~ 0,
r1cdr_final == 0.5 ~ 0,
r1cdr_final == 1 ~ 1,
r1cdr_final == 2 ~ 1,
r1cdr_final == 3 ~ 1
))%>%
mutate(cdr_mci =
case_when(
r1cdr_final == 0 ~ 0,
r1cdr_final == 0.5 ~ 1,
r1cdr_final == 1 ~ 0,
r1cdr_final == 2 ~ 0,
r1cdr_final == 3 ~ 0
))
# Loop for one_var column to define the values in relation to the cutoff scores
for (cutoff in one_var_cutoff) {
col_name <- paste0(test_1, cutoff)
screen_dataset3 <- mutate(screen_dataset3, !!col_name := as.integer(r1jormscore > cutoff))
}
# Create the column name as a combination of the variable of interest and the cutoff score
for (test_1_cutoff in one_var_cutoff) {
comp1_column <- paste0(test_1, test_1_cutoff)
# Create the new column with values equal to if the participant meets the cutoffs or not
screen_dataset3 <- screen_dataset3 %>%
mutate(!!comp1_column := ifelse(get(comp1_column) == 1, 1, 0))
}
# Change the variables of interest to a factor to use within the metric calculations below
screen_dataset3 <- screen_dataset3 %>%
mutate_at(vars(contains(test_1)), as.factor) %>%
mutate_at(vars(contains(test_2)), as.factor)
# Define the screen_variables of interest. Make sure to comment out the one not being used
#screen_variables <- screen_dataset2 %>%
# dplyr::select(jorm3:jorm5)
screen_variables <- screen_dataset3 %>%
dplyr::select(jorm3:jorm5)
# Save the output to a list
screen_list <- as.list(screen_variables)
# Instantiate an empty list
list_output <- list()
for(i in seq_along(screen_list)) {
# Takes the ith name in screen_list and saves to variable name
variable_name <- names(screen_list)[i]
# Creates the confusion matrix comparing the ith outcome in screen_list compared to the defined gold standard and saves to x
x <- caret::confusionMatrix(screen_list[[i]],
gold_std,
positive = "1",
mode = "everything")
# Calculates Youden's Index based on the calculated confusion matrix (x)
y <- youden(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
# Calculates the area under the curve for the ith outcome and gold standard
auc <- pROC::auc(as.numeric(gold_std), as.numeric(screen_list[[i]]))
# Calculates distance from upper left hand corner (where 0 is perfect) for the ith outcome compared to gold standard
roc01 <- roc01(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
# Calculates Matthew's Class Correlation betwen ith outcome of screen_list and gold standard
mcc <- mcc(gold_std, screen_list[[i]])
# Save values to metric names
values <- c(
accuracy = x$overall[metric1],
sensitivity = x$byClass[metric2],
specificity = x$byClass[metric3],
auc <- auc,
distance <- roc01,
#mcc <- mcc,
youden = y,
#neg_pred_value = x$byClass[metric8],
#pos_pred_value = x$byClass[metric9],
cut_off = variable_name
)
# Save the values to the previous instantiated list
list_output[[length(list_output) + 1]] <- values
}
# Convert the values to a table
output_table <- as_tibble(t(data.frame(list_output)))
# Change the column names to the previously defined metrics
new_names <- c(metric1,
metric2,
metric3,
metric4,
metric5,
#metric6,
metric7,
#metric8,
#metric9
"cut_off")
#print(list_output)
names(output_table)[1:7] <- new_names
# Create a table to present the results
screen_table <- output_table
# Pivot the data into a "tidy" format. Instead of having a column for each metric, there is one column defined as metric. This allows each row to be a distinct value
screen_long <- screen_table %>%
pivot_longer(cols = c(metric1,
metric2,
metric3,
metric4,
metric5,
metric7
#metric8,
#metric9,
),
names_to = "Metric",
values_to = "Value")
# Change the value column from character to numeric
screen_long$Value <- as.numeric(screen_long$Value)
# Pivot the data table to a wide format where column names will come from the cut_off values of the second variable of interest (in this case test 2)
screen_wide <- screen_long %>%
pivot_wider(names_from = cut_off, values_from = Value)
# Utilise the package GT for the creation of our table
one_var_table <- gt(screen_wide) %>%
# Create a field of  headings for each cut_off value for the variable of interest (in this case JORM). If changing ensure the label is updated
tab_spanner(
label = "Cut-off JORM",
columns = where(is.numeric)
) %>%
# Format the decimal to 2 places for clarity
fmt_number(
columns = c(starts_with(test_2)),
decimals = 2
) %>%
# Add a border to visually separate the different cutoff values
tab_style(
style =
cell_borders(
sides =  "bottom",
color = "#8B0000",
weight = px(3)
),
locations =
cells_body(
columns = everything(),
rows = Metric == metric7
)
)
# Add title
one_var_table <- one_var_table %>%
tab_header(
title = md("Dementia Screening with JORM"),
subtitle = md("")
)
# Do nothing if one_var==FALSE
} else {}
# print your table
one_var_table
variable_interest <- screen_dataset2$jorm3.8_hmse25
variable_interest <- as.numeric(variable_interest)
jorm_mmse_roc <- pROC::roc(screen_dataset2$cdr, variable_interest)
pROC::auc(jorm_mmse_roc)
ci.auc(jorm_mmse_roc, method = "bootstrap", boot.n = 2000)
plot.roc(jorm_mmse_roc, print.thres = "best",
axes = TRUE,
print.thres.best.method = "youden"
)
optimal_coords <- coords(jorm_mmse_roc, best.method = "youden")
ci.coords(jorm_mmse_roc, x = "best", best.method = "youden", set.seed(321))
one_variable_interest <- screen_dataset3$jorm3.8
one_variable_interest <- as.numeric(one_variable_interest)
jorm_mmse_roc <- pROC::roc(screen_dataset3$cdr, one_variable_interest)
pROC::auc(jorm_mmse_roc)
ci.auc(jorm_mmse_roc, method = "bootstrap", boot.n = 2000)
plot.roc(jorm_mmse_roc, print.thres = "best",
axes = TRUE,
print.thres.best.method = "youden"
)
optimal_coords <- coords(jorm_mmse_roc, best.method = "youden")
ci.coords(jorm_mmse_roc, x = "best", best.method = "youden", set.seed(321))
weight <- quantile(lasi_data$r1wtresp.x, probs = seq(0, 1, 0.25))
lasi_0 <- lasi_data %>%
filter(r1wtresp.x <= 0.0718)
lasi_25 <- lasi_data %>%
filter(r1wtresp.x > 0.0718 & r1wtresp.x <= 0.5239)
lasi_5 <- lasi_data %>%
filter(r1wtresp.x > 0.5239 & r1wtresp.x <= 0.8394)
lasi_75 <- lasi_data %>%
filter(r1wtresp.x > 0.8394 & r1wtresp.x <= 1.5185)
lasi_1 <- lasi_data %>%
filter(r1wtresp.x > 1.5185 & r1wtresp.x <= 2.7734)
# Select relevant variables as well as create two outcomes. One is CDR binary classification where CDR scores of 0 and 0.5 are classified as non-dementia and others are classified as dementia. The other creates a mild cognitive impairment outcome, which is again a binary classification where 0.5 is the positive case and other scores are the negative.
screen_dataset2 <- lasi_1 %>%
dplyr::select(c(
prim_key,
screen_flag,
r1cdr_final,
r1jormscore,
r1hmse_score,
r1iadltot1_d,
r1bl1score,
r1act_trav,
)) %>%
mutate(cdr =
case_when(
r1cdr_final == 0 ~ 0,
r1cdr_final == 0.5 ~ 0,
r1cdr_final == 1 ~ 1,
r1cdr_final == 2 ~ 1,
r1cdr_final == 3 ~ 1
))%>%
mutate(cdr_mci =
case_when(
r1cdr_final == 0 ~ 0,
r1cdr_final == 0.5 ~ 1,
r1cdr_final == 1 ~ 0,
r1cdr_final == 2 ~ 0,
r1cdr_final == 3 ~ 0
))
# Drop missing IADL Total values if being used as a variable
if(params$miss_hmse== "true") {
screen_dataset2 <- screen_dataset2 %>%
drop_na(r1iadltot1_d)
} else {}
# If set to false will be on those without imputed data, if ignore will be on all participants
if (params$miss_hmse== "false" | params$miss_hmse=="ignore"){
{# Loop through different cut-off values for first variable of interest, in this case test_1. test_1 can be replaced by other variables of interest. Ensure you update variable name
for (cutoff in test_1_cutoffs) {
col_name <- paste0(test_1, cutoff)
# Update variable name here if changing
screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1jormscore > cutoff))
}
for (cutoff in test_2_cutoffs) {
# Loop through different cut-off values for second variable of interest, in this case test_2 test_2 can be replaced by other variables of interest. Ensure you update variable name
col_name <- paste0(test_2, cutoff)
# Update variable name here if changing
screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1hmse_score < cutoff))}
}
} else if (params$miss_hmse == "true") {
# Same concept as above. This code exists to assess the quality of non-HMSE variables on participants who had their HMSE data imputed
for (cutoff in test_1_cutoffs) {
col_name <- paste0(test_1, cutoff)
screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1jormscore > cutoff))
}
for (cutoff in test_2_cutoffs) {
col_name <- paste0(test_6, cutoff)
screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(blover > cutoff))
}
for (cutoff in test_4_cutoffs) {
col_name <- paste0(test_4, cutoff)
screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1act_trav == cutoff))
}
}
# If set to false will be on those without imputed data, if ignore will be on all participants
if (params$miss_hmse== "false" | params$miss_hmse=="ignore"){
# The below code is used to create individual columns for two variables of interest and then combine their names and scores
#Loop through each cut-off value for variable 1 and create a column with the associated string (i.e, test_1 relates to "jorm") and the various cut_off values (e.g., jorm3.0, jorm3.1, etc. )
for (test_1_cutoff in test_1_cutoffs) {
comp1_column <- paste0(test_1, test_1_cutoff)
# For each jorm column (e.g., jorm3.0, jorm3.1) loop through each cut-off value for variable 2 and create a column with the associated string (i.e, test_2 relates to "hmse") and the various cut_off values (e.g., hmse20, hmse21, etc. )
for (test_2_cutoff in test_2_cutoffs) {
comp2_column <- paste0(test_2, test_2_cutoff)
# Create the combined column name
combined_column <- paste0(comp1_column, "_", comp2_column)
# Create values for the combined column where for each participant, the combined column value will be 1 if both column 1 AND column 2 have a value of 1
screen_dataset2 <- screen_dataset2 %>%
mutate(!!combined_column := ifelse(get(comp1_column) == 1 & get(comp2_column) == 1, 1, 0))
}
}
}  else if (params$miss_hmse == "true") {
# This is code is the same concept as above. This code exists to assess the quality of non-HMSE variables on participants who had their HMSE data imputed
for (test_1_cutoff in test_1_cutoffs) {
comp1_column <- paste0(test_1, test_1_cutoff)
for (test_6_cutoff in test_6_cutoffs) {
comp3_column <- paste0(test_6, test_6_cutoff)
# Create the combined column name
combined_column <- paste0(comp1_column, "_", comp3_column)
# Create values for the combined column where for each participant, the combined column value will be 1 if both column 1 AND column 2 have a value of 1
screen_dataset2 <- screen_dataset2 %>%
mutate(!!combined_column := ifelse(get(comp1_column) == 1 & get(comp3_column) == 1, 1, 0))
# While the previous code has been the same, the next 10 lines are for adding a third variable if interested in assessing the performance of three columns
for (test_4_cutoff in test_4_cutoffs) {
comp4_column <- paste0(test_4, test_4_cutoff)
# Create the combined column name
combined_column2 <- paste0(combined_column, "_", comp4_column)
# Create the new column
screen_dataset2 <- screen_dataset2 %>%
mutate(!!combined_column2 := ifelse(get(combined_column) == 1 & get(comp4_column) == 1, 1, 0))
}
}
}
}
# Change the columns that contain the associated test names (e.g, test_1 relating to "jorm") to factors. This allows for the variables to be used within the following below metric calculations
screen_dataset2 <- screen_dataset2 %>%
mutate_at(vars(contains(test_1)), as.factor) %>%
mutate_at(vars(contains(test_2)), as.factor) %>%
mutate_at(vars(contains(test_4)), as.factor) %>%
mutate_at(vars(contains(test_6)), as.factor) %>%
mutate_at(vars(contains(comparison_string)), as.factor)
# Select associated variables of interest and cut_off values. For example, if outcomes of interest were "jorm" with cut_off scores between 3 and 5, as well as "hmse" with cut_off values between 21 and 30, the below code will select all relevant columns. Reminder each "jorm" value will have a column for reach "hmse" value (e.g, jorm3_hmse21, jorm3_hmse22...., jorm3.1_hmse21 etc)
# Same code will be run if miss_hmse is ignore or false. If ignore it will be on the whole datset set
if (params$miss_hmse=="false"| params$miss_hmse=="ignore"){
screen_variables <- screen_dataset2 %>%
dplyr::select(jorm3_hmse21:jorm5_hmse30)
} else if (params$miss_hmse=="true")
# Same as the above code but exists to assess the performance of non_HMSE variables on participants with imputed HMSE data.
{
screen_variables <- screen_dataset2 %>%
dplyr::select(jorm3_bl1_trav0:jorm5_bl12_trav1) %>%
dplyr::select(contains("trav"))
}
# Save extracted variables to a list
screen_list <- as.list(screen_variables)
# Instantiate an empty list
list_output <- list()
# Define the outcomes of interest
metric1 <- as.character("Accuracy")
metric2 <- as.character("Sensitivity")
metric3 <- as.character("Specificity")
metric4 <- as.character("AUC")
metric5 <- as.character("Distance")
metric6 <- as.character("Matthew_Class_Correlation")
metric7 <- as.character("Youdens_Index")
metric8 <- as.character("Neg Pred Value")
metric9 <- as.character("Pos Pred Value")
#Define gold standard variables
gold_std <- screen_dataset2$cdr
gold_std2 <- screen_dataset2$cdr_mci
if (params$mci==FALSE) {
for(i in seq_along(screen_list)) {
# Takes the ith name in screen_list and saves to variable name
variable_name <- names(screen_list)[i]
# Creates the confusion matrix comparing the ith outcome in screen_list compared to the defined gold standard and saves to x
x <- caret::confusionMatrix(screen_list[[i]],
gold_std,
positive = "1",
mode = "everything")
# Calculates Youden's Index based on the calculated confusion matrix (x)
y <- youden(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
# Calculates the area under the curve for the ith outcome and gold standard
auc <- pROC::auc(as.numeric(gold_std), as.numeric(screen_list[[i]]))
# Calculates distance from upper left hand corner (where 0 is perfect) for the ith outcome compared to gold standard
roc01 <- roc01(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
# Calculates Matthew's Class Correlation between ith outcome of screen_list and gold standard
mcc <- mcc(gold_std, screen_list[[i]])
# Save values to metric names
values <- c(
accuracy = x$overall[metric1],
sensitivity = x$byClass[metric2],
specificity = x$byClass[metric3],
auc <- auc,
distance <- roc01,
#mcc <- mcc,
youden = y,
#neg_pred_value = x$byClass[metric8],
#pos_pred_value = x$byClass[metric9],
cut_off = variable_name
)
# Output values to the previously instantiated list
list_output[[length(list_output) + 1]] <- values
}
} else {
# This code is the same as above, but with mild cognitive impairment as the outcome rather than dementia
for(i in seq_along(screen_list)){
variable_name <- names(screen_list)[i]
x <- caret::confusionMatrix(screen_list[[i]],
gold_std2,
positive = "1",
mode = "everything")
values <- c(
accuracy = x$overall[metric1],
sensitivity = x$byClass[metric2],
specificity = x$byClass[metric3],
neg_pred_value = x$byClass[metric8],
#cut_off = screen_list[i][i]
cut_off = variable_name
)
list_output[[length(list_output) + 1]] <- values
}
}
# Convert list_output of metric values to a data table
pop_table <- as_tibble(t(data.frame(list_output)))
# Change the names of the columns for the output tables to the previously defined metric names
new_names <- c(metric1,
metric2,
metric3,
metric4,
metric5,
#metric6,
metric7,
#metric8,
#metric9
"cut_off")
#print(list_output)
names(pop_table)[1:7] <- new_names
