---
title: "lasi_dx_ML"
format: 
  html:
    toc: true
    theme: flatly
    embed-resources: true
editor: visual
params:
  # if true will give results of desired variable screen on individuals with imputed HMSE. Changing this will also change the data analysed in the one_var code
  miss_hmse: "false"
  # if true susbet to those who have less than 6 years of education
  edu_low: false
  # if true subset to those who have greater than or equal to 6 years of eudcation
  edu_high: false
  # if true will assess performance in rural communities 
  rural: false
  # if true will assess performance in urban communities
  urban: false
  # If true will assess performance in illiterate individuals
  illiterate: false
  # If true will assess perforamnce in literate individuals
  literate: false
  # Select gender of interest
  gender: "ignore"
  # If true, outcome will be mild cognitive impairment
  mci: false
  # If true, analysis on performance of one outcome measure will be conducted. Performance of multiple outcome measures will always run
  one_var: true
---

# Packages
```{r}
library(tidyverse)
library(broom)
library(nlme)
library(car)
library(haven)
library(caret)
library(gt)
library(gtExtras)
library(rmarkdown)
library(pROC)
library(mltools)
library(cutpointr)
library(yardstick)
library(survey)
```

# Data Cleaning


## Loading necessary datasets 
```{r}
# Add your path to Harmonised LASI DAD Data
H_DAD <- read_dta("/path/to/data/dir/H_DAD.dta")

# Add your path to the Harmonised LASI Data
load("/path/to/data/dir/H_LASI_a3.rdata")
H_LASI_a3 <- as_tibble(H_LASI_a3)

# Remove participants who were not rated on the CDR
H_DAD <- H_DAD %>% 
  filter(!is.na(r1cdr_final))

# Join together the Harmonised LASI and LASI-DAD by participant identifier
lasi_data <- inner_join(H_DAD, H_LASI_a3, by = "prim_key")

```

```{r}

```


## Data Filtering
```{r}
# Filter participants who had an imputed HMSE score. If miss_hmse==TRUE, dataset will be participants who had an imputed score, if false, participants will be those without the imputed score. If ignore it will be the whole dataset. 
if (params$miss_hmse=="true") {
clin_hmse <- H_DAD %>% 
 mutate(hmse_flag = if_else(r1fyr > 3 |
                              r1fyr == 2 |
                               r1fdate > 3 |
                              r1fdate == 2 |
                               r1fdw > 3 |
                              r1fdw == 2 |
                               r1fmo > 3 |
                              r1fmo == 2 |
                               r1fstate > 3 |
                              r1fstate == 2 |
                               r1fcity > 3 |
                              r1fcity == 2 |
                               r1fname > 3 |
                              r1fname == 2 |
                               r1faddress > 3 |
                              r1faddress == 2 |
                               r1fimrc3 > 1 |
                               r1fdlrc3 > 1 |
                               r1fbackwar_d > 1 |
                               r1frepeat > 1 |
                               r1freadfol > 1 & 
                               r1freadfol < 10 |
                               r1fcopyfol > 1 &
                               r1fcopyfol < 10 |
                               r1fexecu > 1 |
                               r1fsay > 1 &
                               r1fsay < 10 |
                               r1fwrite > 1 &
                               r1fwrite < 10 |
                               r1fdraw > 1,
                                 1, 0)) %>% 
  subset(hmse_flag == 1) 
  } else if (params$miss_hmse=="false") {
    clin_hmse <- H_DAD %>% 
 mutate(hmse_flag = if_else(r1fyr > 3 |
                              r1fyr == 2 |
                               r1fdate > 3 |
                              r1fdate == 2 |
                               r1fdw > 3 |
                              r1fdw == 2 |
                               r1fmo > 3 |
                              r1fmo == 2 |
                               r1fstate > 3 |
                              r1fstate == 2 |
                               r1fcity > 3 |
                              r1fcity == 2 |
                               r1fname > 3 |
                              r1fname == 2 |
                               r1faddress > 3 |
                              r1faddress == 2 |
                               r1fimrc3 > 1 |
                               r1fdlrc3 > 1 |
                               r1fbackwar_d > 1 |
                               r1frepeat > 1 |
                               r1freadfol > 1 & 
                               r1freadfol < 10 |
                               r1fcopyfol > 1 &
                               r1fcopyfol < 10 |
                               r1fexecu > 1 |
                               r1fsay > 1 &
                               r1fsay < 10 |
                               r1fwrite > 1 &
                               r1fwrite < 10 |
                               r1fdraw > 1,
                                 1, 0)) %>% 
   subset(hmse_flag == 0) 
  } else if (params$miss_hmse=="ignore") {
    clin_hmse <- H_DAD
    }

# Subset partcipants based on demographic data. For example, if edu_low equals true, remaining participants will be those who had less than 6 years of education
if (params$edu_low==TRUE) {
  clin_hmse <- clin_hmse %>% 
    subset(raedyrs < 6)
} else {}

if (params$edu_high==TRUE) {
  clin_hmse <- clin_hmse %>% 
    subset(raedyrs >= 6)
} else {}

if (params$rural==TRUE) {
  clin_hmse <- clin_hmse %>% 
    subset(h1rural == 1)
} else {}

if (params$urban==TRUE) {
  clin_hmse <- clin_hmse %>% 
    subset(h1rural == 0)
} else {}

if (params$illiterate==TRUE) {
  clin_hmse <- clin_hmse %>% 
    subset(r1illiterate == 1)
} else {}

if (params$literate==TRUE) {
  clin_hmse <- clin_hmse %>% 
    subset(r1illiterate == 0)
} else {}

if (params$gender == "male"){
  clin_hmse <- clin_hmse %>% 
  subset(ragender==1)
} else if (params$gender == "female") {
    clin_hmse <- clin_hmse %>% 
      subset(ragender==2)
} else if (params$gender == "ignore") {}

```


```{r}

# Change name to screen dataset which will be transferable across following functions. Additionally, an overall blessed test score is calculated and added to the dataset
screen_dataset <- clin_hmse %>% 
  mutate(blover = r1bl1score + r1bl2score)



# Define ID Variables
id <- screen_dataset$prim_key

# Flag variable for completeness of outcome if needed
screen_flag <- screen_dataset$hmse_flag



# Define tests and comparison strings for data manipulation
test_1 <- as.character("jorm")
test_2 <- as.character("hmse")
test_3 <- as.character("iadl")
test_4 <- as.character("trav")
test_5 <- as.character("bl1")
test_6 <- as.character("bl")
#test_5 <- as.character("bl2")
comparison_string <- as.character("cdr")

# Define cutoff scores with which to compare against CDR rating. For example test_1_cutoffs will create a sequence from 3 to 5 counting by 0.1 equating jorm scores ranging from 3.0 to 5.0
test_1_cutoffs <- seq(3, 5, 0.1)
test_2_cutoffs <- seq(20, 30, 1)
test_3_cutoffs <- seq(0, 7, 1)
test_4_cutoffs <- seq(0, 1, 1)
test_5_cutoffs <- seq(0, 8, 0.5)
test_6_cutoffs <- seq(0, 12, 0.1)
```


# Two Variable Outcomes

The following code is used for the comparison of criteria from combined outcome measures (>= 2) compared to LASI-DAD Clinical Dementia Rating (CDR). These can be the variables defined above (test_1, test_2, etc.) or newly created by the user

```{r}
# Select relevant variables as well as create two outcomes. One is CDR binary classification where CDR scores of 0 and 0.5 are classified as non-dementia and others are classified as dementia. The other creates a mild cognitive impairment outcome, which is again a binary classification where 0.5 is the positive case and other scores are the negative.
screen_dataset2 <- screen_dataset %>% 
  dplyr::select(c(
    prim_key,
    screen_flag,
    r1cdr_final,
    r1jormscore,
    r1hmse_score,
    r1iadltot1_d,
    r1bl1score,
    r1act_trav,
    r1wtresp,
    blover)) %>% 
    mutate(cdr =
           case_when(
             r1cdr_final == 0 ~ 0,
             r1cdr_final == 0.5 ~ 0,
             r1cdr_final == 1 ~ 1,
             r1cdr_final == 2 ~ 1,
             r1cdr_final == 3 ~ 1
           ))%>% 
    mutate(cdr_mci =
           case_when(
             r1cdr_final == 0 ~ 0,
             r1cdr_final == 0.5 ~ 1,
             r1cdr_final == 1 ~ 0,
             r1cdr_final == 2 ~ 0,
             r1cdr_final == 3 ~ 0
           ))

# Drop missing IADL Total values if being used as a variable
if(params$miss_hmse== "true") {
  screen_dataset2 <- screen_dataset2 
  #%>% 
   # drop_na(r1iadltot1_d)
} else {}

# If set to false will be on those without imputed data, if ignore will be on all participants
if (params$miss_hmse== "false" | params$miss_hmse=="ignore"){
{# Loop through different cut-off values for first variable of interest, in this case test_1. test_1 can be replaced by other variables of interest. Ensure you update variable name
for (cutoff in test_1_cutoffs) {
  col_name <- paste0(test_1, cutoff)
  # Update variable name here if changing 
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1jormscore > cutoff))
}

for (cutoff in test_2_cutoffs) {
  # Loop through different cut-off values for second variable of interest, in this case test_2 test_2 can be replaced by other variables of interest. Ensure you update variable name
  col_name <- paste0(test_2, cutoff)
   # Update variable name here if changing 
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1hmse_score < cutoff))}

}
  
} else if (params$miss_hmse == "true") {
  # Same concept as above. This code exists to assess the quality of non-HMSE variables on participants who had their HMSE data imputed
 for (cutoff in test_1_cutoffs) {
  col_name <- paste0(test_1, cutoff)
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1jormscore > cutoff))
 }
  
 for (cutoff in test_4_cutoffs) {
  col_name <- paste0(test_4, cutoff)
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1act_trav < cutoff))
  } 
#for (cutoff in test_5_cutoffs) {
#  col_name <- paste0(test_5, cutoff)
#  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1bl1score > cutoff))
#}
} 

# If set to false will be on those without imputed data, if ignore will be on all participants
if (params$miss_hmse== "false" | params$miss_hmse=="ignore"){

# The below code is used to create individual columns for two variables of interest and then combine their names and scores
  
#Loop through each cut-off value for variable 1 and create a column with the associated string (i.e, test_1 relates to "jorm") and the various cut_off values (e.g., jorm3.0, jorm3.1, etc. )
for (test_1_cutoff in test_1_cutoffs) {
  comp1_column <- paste0(test_1, test_1_cutoff)
  
  # For each jorm column (e.g., jorm3.0, jorm3.1) loop through each cut-off value for variable 2 and create a column with the associated string (i.e, test_2 relates to "hmse") and the various cut_off values (e.g., hmse20, hmse21, etc. )
  for (test_2_cutoff in test_2_cutoffs) {
    comp2_column <- paste0(test_2, test_2_cutoff)
    
    # Create the combined column name
    combined_column <- paste0(comp1_column, "_", comp2_column)
    
    # Create values for the combined column where for each participant, the combined column value will be 1 if both column 1 AND column 2 have a value of 1
    screen_dataset2 <- screen_dataset2 %>% 
      mutate(!!combined_column := ifelse(get(comp1_column) == 1 & get(comp2_column) == 1, 1, 0))
    
    
  }
}
}  else if (params$miss_hmse == "true") {
  
# This is code is the same concept as above. This code exists to assess the quality of non-HMSE variables on participants who had their HMSE data imputed
 for (test_1_cutoff in test_1_cutoffs) {
  comp1_column <- paste0(test_1, test_1_cutoff)
  
  # For each jorm column (e.g., jorm3.0, jorm3.1) loop through each cut-off value for variable 2 and create a column with the associated string (i.e, test_2 relates to "hmse") and the various cut_off values (e.g., hmse20, hmse21, etc. )
  for (test_4_cutoff in test_4_cutoffs) {
    comp2_column <- paste0(test_4, test_4_cutoff)
    
    # Create the combined column name
    combined_column <- paste0(comp1_column, "_", comp2_column)
    
    # Create values for the combined column where for each participant, the combined column value will be 1 if both column 1 AND column 2 have a value of 1
    screen_dataset2 <- screen_dataset2 %>% 
      mutate(!!combined_column := ifelse(get(comp1_column) == 1 & get(comp2_column) == 1, 1, 0)) 
    
    # While the previous code has been the same, the next 10 lines are for adding a third variable if interested in assessing the performance of three columns
    # for (test_5_cutoff in test_5_cutoffs) {
    # comp4_column <- paste0(test_5, test_5_cutoff)
    
        # Create the combined column name
   # combined_column2 <- paste0(combined_column, "_", comp4_column)
    
    # Create the new column
   # screen_dataset2 <- screen_dataset2 %>% 
    #  mutate(!!combined_column2 := ifelse(get(comp1_column) == 1 & get(comp2_column) == 1 |
    #                                       get(comp1_column) == 1 & get(comp4_column) == 1 |
      #                                      get(comp2_column) == 1 & get(comp4_column) == 1, 1, 0))
   # }
    
  
   }
  
  }
} 
# Change the columns that contain the associated test names (e.g, test_1 relating to "jorm") to factors. This allows for the variables to be used within the following below metric calculations
screen_dataset2 <- screen_dataset2 %>% 
  mutate_at(vars(contains(test_1)), as.factor) %>% 
  mutate_at(vars(contains(test_2)), as.factor) %>% 
  mutate_at(vars(contains(test_4)), as.factor) %>% 
  mutate_at(vars(contains(test_6)), as.factor) %>% 
  mutate_at(vars(contains(comparison_string)), as.factor)

```




```{r}

# Select associated variables of interest and cut_off values. For example, if outcomes of interest were "jorm" with cut_off scores between 3 and 5, as well as "hmse" with cut_off values between 21 and 30, the below code will select all relevant columns. Reminder each "jorm" value will have a column for reach "hmse" value (e.g, jorm3_hmse21, jorm3_hmse22...., jorm3.1_hmse21 etc)
# Same code will be run if miss_hmse is ignore or false. If ignore it will be on the whole datset set
if (params$miss_hmse=="false"| params$miss_hmse=="ignore"){
screen_variables <- screen_dataset2 %>% 
  dplyr::select(jorm3_hmse20:jorm5_hmse30)
} else if (params$miss_hmse=="true")
# Same as the above code but exists to assess the performance of non_HMSE variables on participants with imputed HMSE data. 
  {
  screen_variables <- screen_dataset2 %>% 
     dplyr::select(jorm3_trav0:jorm5_trav1) 
  #%>% 
   # dplyr::select(contains("trav"))
}
# Save extracted variables to a list
screen_list <- as.list(screen_variables)

# Instantiate an empty list
list_output <- list()

# Define the outcomes of interest
metric1 <- as.character("Accuracy")
metric2 <- as.character("Sensitivity")
metric3 <- as.character("Specificity")
metric4 <- as.character("AUC")
metric5 <- as.character("Distance")
metric6 <- as.character("Matthew_Class_Correlation")
metric7 <- as.character("Youdens_Index")
metric8 <- as.character("Neg Pred Value")
metric9 <- as.character("Pos Pred Value")

#Define gold standard variables

gold_std <- screen_dataset2$cdr
gold_std2 <- screen_dataset2$cdr_mci 



if (params$mci==FALSE) {
for(i in seq_along(screen_list)) {
  # Takes the ith name in screen_list and saves to variable name
    variable_name <- names(screen_list)[i]
    # Creates the confusion matrix comparing the ith outcome in screen_list compared to the defined gold standard and saves to x
   x <- caret::confusionMatrix(screen_list[[i]], 
                        gold_std,
                        positive = "1",
                        mode = "everything")
   # Calculates Youden's Index based on the calculated confusion matrix (x)
   y <- youden(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
   # Calculates the area under the curve for the ith outcome and gold standard
   auc <- pROC::auc(as.numeric(gold_std), as.numeric(screen_list[[i]]))
   # Calculates distance from upper left hand corner (where 0 is perfect) for the ith outcome compared to gold standard
   roc01 <- roc01(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
   # Calculates Matthew's Class Correlation between ith outcome of screen_list and gold standard
   #mcc <- mcc(gold_std, screen_list[[i]])

   # Save values to metric names
   values <- c(
     accuracy = x$overall[metric1],
     sensitivity = x$byClass[metric2],
     specificity = x$byClass[metric3],
     auc <- auc,
     distance <- roc01,
     #mcc <- mcc,
     youden = y,
     #neg_pred_value = x$byClass[metric8],
     #pos_pred_value = x$byClass[metric9],
     cut_off = variable_name
  )
   # Output values to the previously instantiated list
  list_output[[length(list_output) + 1]] <- values
}

} else {
  # This code is the same as above, but with mild cognitive impairment as the outcome rather than dementia
  for(i in seq_along(screen_list)){
    variable_name <- names(screen_list)[i]
   x <- caret::confusionMatrix(screen_list[[i]], 
                        gold_std2,
                        positive = "1",
                        mode = "everything")
   values <- c(
     accuracy = x$overall[metric1],
     sensitivity = x$byClass[metric2],
     specificity = x$byClass[metric3],
     neg_pred_value = x$byClass[metric8],
     #cut_off = screen_list[i][i]
     cut_off = variable_name
  )
   
  list_output[[length(list_output) + 1]] <- values
}
}
# Convert list_output of metric values to a data table
output_table <- as_tibble(t(data.frame(list_output)))
# Change the names of the columns for the output tables to the previously defined metric names
new_names <- c(metric1,
               metric2,
               metric3,
               metric4,
               metric5,
               #metric6,
               metric7,
               #metric8,
               #metric9
               "cut_off")
#print(list_output)
names(output_table)[1:7] <- new_names
```

## This code is used to create a table where the metrics are comparing results of comparison of combination measures against the LASI-DAD Clinical Dementia Rating

```{r}

# If set to false will be on those without imputed data, if ignore will be on all participants
if (params$miss_hmse== "false" | params$miss_hmse=="ignore"){
screen_table <- output_table %>%
  # Separate the combined column into two names. This will allow for the creation of a table where the intersection of two variable cut-offs (e.g., jorm3 and hmse21) will be the resultant metric
  separate(col = "cut_off", into = c(test_1, test_2), sep = "_", extra = "merge")

# Pivot the data into a "tidy" format. Instead of having a column for each metric, there is one column defined as metric. This allows each row to be a distinct value
screen_long <- screen_table %>%
  pivot_longer(cols = c(metric1,
                        metric2,
                        metric3,
                        metric4,
                        metric5,
                        metric7
                        #metric8,
                        #metric9,
                        ),
               names_to = "Metric",
               values_to = "Value")

# Change the value column from character to numeric
screen_long$Value <- as.numeric(screen_long$Value)

# Pivot the data table to a wide format where column names will come from the cut_off values of the second variable of interest (in this case test 2)
screen_wide <- screen_long %>% 
  pivot_wider(names_from = test_2, values_from = Value)


# Utilise the package gt for the creation of our table
your_table <- gt(screen_wide) %>%
  # Create a field of  headings for each cut_off value for the second variable of interest (in this case HMSE)
  tab_spanner(
    label = "Cut-off HMSE",
    columns = where(is.numeric)
  ) %>%
  # Format the decimal to two places for clarity
  fmt_number(
    columns = c(starts_with(test_2)),
    decimals = 2
  ) %>%
  # Create a field of headings for each cut_off value for the first variable of interest (in this case JORM)
  tab_spanner(
    label = "Cut-off Jorm",
    columns = starts_with(test_1)
  ) %>%
  # Format the decial to two places for clarity
  fmt_number(
    columns = c(starts_with(test_1)),
    decimals = 2
  ) %>% 
  # Add a red border at the bottom of metric7 (or whichever the last metric of interest is). This provides a nice visual aid to track moving to the next cut_off score
  tab_style(   
    style =
      cell_borders(
        sides =  "bottom",
        color = "#8B0000",
        weight = px(3)
    ),
    locations =
      cells_body(
        columns = everything(),
        rows = Metric == metric7
    )
  )
# Add a title and title to the table
your_table <- your_table %>% 
      tab_header(
        title = md("Dementia Screening with JORM and HMSE"),
        subtitle = md("All participants had a complete HMSE")
      )
} else {
  # This code is the same concept as the above but exists to present the performance of non-HMSE variables on participants who's HMSE scores were imputed
screen_table <- output_table %>%
  separate(col = "cut_off", into = c(test_1, test_2), sep = "_", extra = "merge")

screen_long <- screen_table %>%
  pivot_longer(cols = c(metric1,
                        metric2,
                        metric3,
                        metric4,
                        metric5,
                        #metric6,
                        metric7
                        #metric8,
                        #metric9
                        ),
               names_to = "Metric",
               values_to = "Value")


screen_long$Value <- as.numeric(screen_long$Value)

screen_wide <- screen_long %>% 
  pivot_wider(names_from = test_2, values_from = Value)

your_table <- gt(screen_wide) %>%
  tab_spanner(
    label = "Cut-off HMSE",
    columns = where(is.numeric)
  ) %>%
  fmt_number(
    columns = c(starts_with(test_2)),
    decimals = 2
  ) %>%
  tab_spanner(
    label = "Cut-off Jorm",
    columns = starts_with(test_1)
    
  ) %>%
  fmt_number(
    columns = c(starts_with(test_1)),
    decimals = 2
  ) %>% 
  tab_style(   
    style =
      cell_borders(
        sides =  "bottom",
        color = "#8B0000",
        weight = px(3)
    ),
    locations =
      cells_body(
        columns = everything(),
        rows = Metric == metric7
    )
  )
your_table <- your_table %>% 
      tab_header(
        title = md("Dementia Screening with JORM and IADL"),
        subtitle = md("All participants had imputed data with HMSE")
      )
}

# Add footnote stating the comparison outcome
if(params$mci==FALSE) {
  your_table <- your_table %>% 
    # Comparison outcome is Dementia (> 0.5 on the CDR)
    tab_footnote(
      footnote = md("Comparison Outcome is Clinical Dementia Rating where > 0.5 signifies dementia")
    ) %>% 
    # Add footnote defining Youden's Index
    tab_footnote(
      footnote = md("Youden's Index = Sensitivity + Specificity - 1. Higher is better")
    ) %>% 
    # Add footnote defining distance metric
     tab_footnote(
      footnote = md("Distance = distance from upper left corner or perfect discrimination. Lower is better")
    )
} else {
  # Add footnote for when comparion is mild cognitive impairment
  your_table <- your_table %>% 
    tab_footnote(
      footnote = md("Comparison Outcome in Clinical Dementia Rating of Mild Cognitive Impairment (0.5)")
    )
}

if(params$edu_low==TRUE) {
  your_table <- your_table %>% 
    tab_footnote(
      footnote = md("All participants < 6 years education")
    )
} else {}

# The below code adds footnotes if sub-demographics of the population were assessed (e.g, participants with >= 6 years of education)
if(params$edu_high==TRUE) {
  your_table <- your_table %>% 
    tab_footnote(
      footnote = md("All participants >= 6 years education")
    )
} else {}

if (params$rural) {your_table <- your_table %>% 
    tab_footnote(
      footnote = md("All participants from rural communities")
    )
} else {}

if (params$urban) {your_table <- your_table %>% 
    tab_footnote(
      footnote = md("All participants from urban communities")
    )
} else {}

if (params$illiterate) {your_table <- your_table %>% 
    tab_footnote(
      footnote = md("All participants can not read or write")
    )
} else {}

if (params$literate) {your_table <- your_table %>% 
    tab_footnote(
      footnote = md("All participants can read or write")
    )
} else {}

if (params$gender == "male"){
    your_table <- your_table %>% 
  tab_footnote(
      footnote = md("Only Males")
    )
} else if (params$gender == "female") {
     your_table <- your_table %>% 
  tab_footnote(
      footnote = md("Only Females")
    )
} else if (params$gender == "ignore") {}

# Add color to better scoring values to more easily identify top performers
your_table <- your_table %>% 
  data_color(
    columns = everything(),
    # Color the metrics where higher scores indicate better performance
    rows = Metric %in% c(
      "Accuracy",
      "Sensitivity",
      "Specificity",
      "AUC",
      "Matthew_Class_Correlation",
      "Youdens_Index"
    ),
    method = "numeric",
    domain = c(0.85, 1.0),
    palette = "GnBu",
    na_color = "lightgrey"
  ) %>% 
  # Color the metrics where lower scores indicate better performance, those this is not consistently reflected in the table output
  data_color(
    columns = everything(),
    rows = Metric %in% c(
      "Distance"
    ),
    method = "numeric",
    domain = c(0.0, 0.25),
    palette = "GnBu",
    na_color = "lightgrey",
    reverse = TRUE
  )

# Print the table
your_table
```

```{r}
screen_cdr <- screen_dataset2 %>% 
  dplyr::filter(jorm3.8_hmse25 == 1 & cdr == 0)
```


```{r}
screen_trial <- screen_dataset2 %>% 
  dplyr::mutate(three_outcome = ifelse((as.numeric(as.character(r1jormscore)) > 3.8 & as.numeric(as.character(r1bl1score)) > 2.0) |
                                         (as.numeric(as.character(r1jormscore)) > 3.8 & as.numeric(as.character(r1hmse_score) < 21)) |
                                         (as.numeric(as.character(r1bl1score)) > 2.0 & as.numeric(as.character(r1hmse_score)) < 21), 1, 0))


y = confusionMatrix(screen_dataset2$jorm3.8_hmse25, screen_dataset2$cdr, positive = "1", mode = "everything")

```


```{r}
# Create survey design object
svy_design <- svydesign(ids = ~1, weights = ~r1wtresp, data = screen_dataset2)


# Update survey design with new column
svy_design <- update(svy_design, actual = cdr, pred_class = screen_dataset2$jorm3.8_hmse25)

# Calculate confusion matrix components
confusion_matrix <- svytable(~ actual + pred_class, svy_design)
print(confusion_matrix)

tn <- confusion_matrix[1, 1]  # True Negatives
fp <- confusion_matrix[1, 2]  # False Positives
fn <- confusion_matrix[2, 1]  # False Negatives
tp <- confusion_matrix[2, 2]  # True Positives

# Sensitivity (True Positive Rate)
sensitivity <- tp / (tp + fn)
print(sensitivity)

# Specificity (True Negative Rate)
specificity <- tn / (tn + fp)
print(specificity)

accuracy <- (tp + tn) / (tp + tn + fp + fn)
print(accuracy)


YI = ((sensitivity + specificity) - 1)
print(YI)


var_sen = ((tp*fn)/(tp+fn)^3)

var_spec = ((fp*tn)/(fp+tn)^3)

cov_sen_spec = (((specificity^2) - 1) * var_sen) + (((sensitivity^2) - 1) * var_spec)

var_youden = var_sen + var_spec + (2*cov_sen_spec)

std_error_youden = sqrt(var_youden)


upper_bound = YI + (1.96*std_error_youden)
lower_bound = YI - (1.96*std_error_youden)


```

# Single Variable Outcome 

The below code is a conceptual repeat of the previous code. However, this exists to assess the performance of only one variable rather than a combination. This code will only be run if the one_var parameter is set to true. The previous code will run despite changes to this parameter

```{r}
if(params$one_var==TRUE) {
  
  
# Define the cutoff of the variable of interest. Uncomment the variable of interest and ensure the other is commented out  
# JORM one var cutoff  
#one_var_cutoff <- seq(3, 5, 0.1)

# HMSE one var cutoff
one_var_cutoff <- seq(15, 30, 1) 

# Define tests and gold standards strings for data manipulation
test_1 <- as.character("jorm")
test_2 <- as.character("hmse")


# Define the outcomes (cdr is positive for participants with a score of > 0.5 on the CDR, cdr_mci is positive for participants with a score of 0.5 on the CDR)
screen_dataset3 <- screen_dataset %>% 
  dplyr::select(c(
    prim_key,
    screen_flag,
    r1cdr_final,
    r1jormscore,
    r1hmse_score,
    r1iadltot1_d,
    r1bl1score,
    r1act_trav,
    blover
  )) %>% 
    mutate(cdr =
           case_when(
             r1cdr_final == 0 ~ 0,
             r1cdr_final == 0.5 ~ 0,
             r1cdr_final == 1 ~ 1,
             r1cdr_final == 2 ~ 1,
             r1cdr_final == 3 ~ 1
           ))%>% 
    mutate(cdr_mci =
           case_when(
             r1cdr_final == 0 ~ 0,
             r1cdr_final == 0.5 ~ 1,
             r1cdr_final == 1 ~ 0,
             r1cdr_final == 2 ~ 0,
             r1cdr_final == 3 ~ 0
           ))



  # Loop for one_var column to define the values in relation to the cutoff scores
for (cutoff in one_var_cutoff) {
  col_name <- paste0(test_2, cutoff)
  screen_dataset3 <- mutate(screen_dataset3, !!col_name := as.integer(r1hmse_score < cutoff))
}
  # Create the column name as a combination of the variable of interest and the cutoff score
for (test_2_cutoff in one_var_cutoff) {
  comp1_column <- paste0(test_2, test_2_cutoff)
  
  # Create the new column with values equal to if the participant meets the cutoffs or not
  screen_dataset3 <- screen_dataset3 %>% 
    mutate(!!comp1_column := ifelse(get(comp1_column) == 1, 1, 0))
}

# Change the variables of interest to a factor to use within the metric calculations below
screen_dataset3 <- screen_dataset3 %>% 
  mutate_at(vars(contains(test_1)), as.factor) %>% 
  mutate_at(vars(contains(test_2)), as.factor)


# Define the screen_variables of interest. Make sure to comment out the one not being used
#screen_variables <- screen_dataset2 %>% 
 # dplyr::select(jorm3:jorm5)
  
screen_variables <- screen_dataset3 %>% 
  dplyr::select(hmse15:hmse30)

# Save the output to a list
screen_list <- as.list(screen_variables)

# Instantiate an empty list
list_output <- list()

for(i in seq_along(screen_list)) {
    # Takes the ith name in screen_list and saves to variable name
    variable_name <- names(screen_list)[i]
        # Creates the confusion matrix comparing the ith outcome in screen_list compared to the defined gold standard and saves to x
   x <- caret::confusionMatrix(screen_list[[i]], 
                        gold_std,
                        positive = "1",
                        mode = "everything")
   # Calculates Youden's Index based on the calculated confusion matrix (x)
   y <- youden(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
   # Calculates the area under the curve for the ith outcome and gold standard
   auc <- pROC::auc(as.numeric(gold_std), as.numeric(screen_list[[i]]))
   # Calculates distance from upper left hand corner (where 0 is perfect) for the ith outcome compared to gold standard
   roc01 <- roc01(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
   # Calculates Matthew's Class Correlation betwen ith outcome of screen_list and gold standard
  # mcc <- mcc(gold_std, screen_list[[i]])
   # Save values to metric names
   values <- c(
     accuracy = x$overall[metric1],
     sensitivity = x$byClass[metric2],
     specificity = x$byClass[metric3],
     auc <- auc,
     distance <- roc01,
     #mcc <- mcc,
     youden = y,
     #neg_pred_value = x$byClass[metric8],
     #pos_pred_value = x$byClass[metric9],
     cut_off = variable_name
   )
   # Save the values to the previous instantiated list
     list_output[[length(list_output) + 1]] <- values
}

# Convert the values to a table
output_table <- as_tibble(t(data.frame(list_output)))
# Change the column names to the previously defined metrics
new_names <- c(metric1,
               metric2,
               metric3,
               metric4,
               metric5,
               #metric6,
               metric7,
               #metric8,
               #metric9
               "cut_off")
#print(list_output)
names(output_table)[1:7] <- new_names

# Create a table to present the results
screen_table <- output_table 
# Pivot the data into a "tidy" format. Instead of having a column for each metric, there is one column defined as metric. This allows each row to be a distinct value
screen_long <- screen_table %>%
  pivot_longer(cols = c(metric1,
                        metric2,
                        metric3,
                        metric4,
                        metric5,
                        metric7
                        #metric8,
                        #metric9,
                        ),
               names_to = "Metric",
               values_to = "Value")

# Change the value column from character to numeric
screen_long$Value <- as.numeric(screen_long$Value)

# Pivot the data table to a wide format where column names will come from the cut_off values of the second variable of interest (in this case test 2)
screen_wide <- screen_long %>% 
  pivot_wider(names_from = cut_off, values_from = Value)

# Utilise the package GT for the creation of our table
one_var_table <- gt(screen_wide) %>%
  # Create a field of  headings for each cut_off value for the variable of interest (in this case JORM). If changing ensure the label is updated
  tab_spanner(
    label = "Cut-off JORM",
    columns = where(is.numeric)
  ) %>%
  # Format the decimal to 2 places for clarity
  fmt_number(
    columns = c(starts_with(test_2)),
    decimals = 2
  ) %>%
  # Add a border to visually separate the different cutoff values
  tab_style(   
    style =
      cell_borders(
        sides =  "bottom",
        color = "#8B0000",
        weight = px(3)
    ),
    locations =
      cells_body(
        columns = everything(),
        rows = Metric == metric7
    )
  )
# Add title
one_var_table <- one_var_table %>% 
      tab_header(
        title = md("Dementia Screening with JORM"),
        subtitle = md("")
      )
# Do nothing if one_var==FALSE
} else {}

# print your table
one_var_table
```



# Code for creating confidence intervals

## Two Variable
```{r}
variable_interest <- screen_trial$jorm3.8_hmse25

variable_interest <- as.numeric(variable_interest)
jorm_mmse_roc <- pROC::roc(screen_trial$cdr, variable_interest)

pROC::auc(jorm_mmse_roc)
ci.auc(jorm_mmse_roc, method = "bootstrap", boot.n = 2000)
```

```{r}
 plot.roc(jorm_mmse_roc, print.thres = "best",
          axes = TRUE,
          print.thres.best.method = "youden"
          )
```


```{r}
optimal_coords <- coords(jorm_mmse_roc, best.method = "youden")
```


```{r}
ci.coords(jorm_mmse_roc, x = "best", best.method = "youden", set.seed(321))
```

```{r}

y = confusionMatrix(as.factor(screen_trial$jorm3.8_hmse25), screen_trial$cdr, positive = "1", mode = "everything")

TP = y$table[2,2]
FP = y$table[2,1]
TN = y$table[1,1]
FN = y$table[1,2]

sen = (TP/(TP + FN))

spec = (TN/(FP + TN))

var_sen = ((TP*FN)/(TP+FN)^3)

var_spec = ((FP*TN)/(FP+TN)^3)

cov_sen_spec = (((spec^2) - 1) * var_sen) + (((sen^2) - 1) * var_spec)

var_youden = var_sen + var_spec + (2*cov_sen_spec)

std_error_youden = sqrt(var_youden)

youden = (sen + spec) - 1

upper_bound = youden + (1.96*std_error_youden)

lower_bound = youden - (1.96*std_error_youden)

acc = ((TP+TN)/(TP+TN+FP+FN))
```



## One Variable
```{r}
one_variable_interest <- screen_dataset3$hmse20

one_variable_interest <- as.numeric(one_variable_interest)
jorm_mmse_roc <- pROC::roc(screen_dataset3$cdr, one_variable_interest)

pROC::auc(jorm_mmse_roc)
ci.auc(jorm_mmse_roc, method = "bootstrap", boot.n = 2000)
```

```{r}
 plot.roc(jorm_mmse_roc, print.thres = "best",
          axes = TRUE,
          print.thres.best.method = "youden"
          )
```


```{r}
optimal_coords <- coords(jorm_mmse_roc, best.method = "youden")
```


```{r}
ci.coords(jorm_mmse_roc, x = "best", best.method = "youden", set.seed(321))
```

```{r}

z = confusionMatrix(screen_dataset2$hmse20, screen_dataset2$cdr, positive = "1", mode = "everything")

TP = z$table[2,2]
FP = z$table[2,1]
TN = z$table[1,1]
FN = z$table[1,2]

sen = (TP/(TP + FN))

spec = (TN/(FP + TN))

var_sen = ((TP*FN)/(TP+FN)^3)

var_spec = ((FP*TN)/(FP+TN)^3)

cov_sen_spec = (((spec^2) - 1) * var_sen) + (((sen^2) - 1) * var_spec)

var_youden = var_sen + var_spec + (2*cov_sen_spec)

std_error_youden = sqrt(var_youden)

youden = (sen + spec) - 1

upper_bound = youden + (1.96*std_error_youden)

lower_bound = youden - (1.96*std_error_youden)
```

## Calculating performance of cutoffs for population weights




```{r}
weight <- quantile(lasi_data$r1wtresp.x, probs = seq(0, 1, 0.25))
```

```{r}
lasi_0 <- lasi_data %>% 
  filter(r1wtresp.x <= 0.0718)


lasi_25 <- lasi_data %>% 
  filter(r1wtresp.x > 0.0718 & r1wtresp.x <= 0.5239)


lasi_5 <- lasi_data %>% 
  filter(r1wtresp.x > 0.5239 & r1wtresp.x <= 0.8394)


lasi_75 <- lasi_data %>% 
  filter(r1wtresp.x > 0.8394 & r1wtresp.x <= 1.5185)


lasi_1 <- lasi_data %>% 
  filter(r1wtresp.x > 1.5185 & r1wtresp.x <= 2.7734)
```

```{r}
# Select relevant variables as well as create two outcomes. One is CDR binary classification where CDR scores of 0 and 0.5 are classified as non-dementia and others are classified as dementia. The other creates a mild cognitive impairment outcome, which is again a binary classification where 0.5 is the positive case and other scores are the negative.
screen_dataset2 <- lasi_1 %>% 
  dplyr::select(c(
    prim_key,
    screen_flag,
    r1cdr_final,
    r1jormscore,
    r1hmse_score,
    r1iadltot1_d,
    r1bl1score,
    r1act_trav,
    r1wtresp.x
    )) %>% 
    mutate(cdr =
           case_when(
             r1cdr_final == 0 ~ 0,
             r1cdr_final == 0.5 ~ 0,
             r1cdr_final == 1 ~ 1,
             r1cdr_final == 2 ~ 1,
             r1cdr_final == 3 ~ 1
           ))%>% 
    mutate(cdr_mci =
           case_when(
             r1cdr_final == 0 ~ 0,
             r1cdr_final == 0.5 ~ 1,
             r1cdr_final == 1 ~ 0,
             r1cdr_final == 2 ~ 0,
             r1cdr_final == 3 ~ 0
           ))

# Drop missing IADL Total values if being used as a variable
if(params$miss_hmse== "true") {
  screen_dataset2 <- screen_dataset2 %>% 
    drop_na(r1iadltot1_d)
} else {}

# If set to false will be on those without imputed data, if ignore will be on all participants
if (params$miss_hmse== "false" | params$miss_hmse=="ignore"){
{# Loop through different cut-off values for first variable of interest, in this case test_1. test_1 can be replaced by other variables of interest. Ensure you update variable name
for (cutoff in test_1_cutoffs) {
  col_name <- paste0(test_1, cutoff)
  # Update variable name here if changing 
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1jormscore > cutoff))
}

for (cutoff in test_2_cutoffs) {
  # Loop through different cut-off values for second variable of interest, in this case test_2 test_2 can be replaced by other variables of interest. Ensure you update variable name
  col_name <- paste0(test_2, cutoff)
   # Update variable name here if changing 
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1hmse_score < cutoff))}
}
  
} else if (params$miss_hmse == "true") {
  # Same concept as above. This code exists to assess the quality of non-HMSE variables on participants who had their HMSE data imputed
for (cutoff in test_1_cutoffs) {
  col_name <- paste0(test_1, cutoff)
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1jormscore > cutoff))
}
for (cutoff in test_2_cutoffs) {
  col_name <- paste0(test_6, cutoff)
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(blover > cutoff))
  } 
for (cutoff in test_4_cutoffs) {
  col_name <- paste0(test_4, cutoff)
  screen_dataset2 <- mutate(screen_dataset2, !!col_name := as.integer(r1act_trav == cutoff))
}
} 

# If set to false will be on those without imputed data, if ignore will be on all participants
if (params$miss_hmse== "false" | params$miss_hmse=="ignore"){

# The below code is used to create individual columns for two variables of interest and then combine their names and scores
  
#Loop through each cut-off value for variable 1 and create a column with the associated string (i.e, test_1 relates to "jorm") and the various cut_off values (e.g., jorm3.0, jorm3.1, etc. )
for (test_1_cutoff in test_1_cutoffs) {
  comp1_column <- paste0(test_1, test_1_cutoff)
  
  # For each jorm column (e.g., jorm3.0, jorm3.1) loop through each cut-off value for variable 2 and create a column with the associated string (i.e, test_2 relates to "hmse") and the various cut_off values (e.g., hmse20, hmse21, etc. )
  for (test_2_cutoff in test_2_cutoffs) {
    comp2_column <- paste0(test_2, test_2_cutoff)
    
    # Create the combined column name
    combined_column <- paste0(comp1_column, "_", comp2_column)
    
    # Create values for the combined column where for each participant, the combined column value will be 1 if both column 1 AND column 2 have a value of 1
    screen_dataset2 <- screen_dataset2 %>% 
      mutate(!!combined_column := ifelse(get(comp1_column) == 1 & get(comp2_column) == 1, 1, 0))
  
  }
}
}  else if (params$miss_hmse == "true") {
  
# This is code is the same concept as above. This code exists to assess the quality of non-HMSE variables on participants who had their HMSE data imputed
  for (test_1_cutoff in test_1_cutoffs) {
  comp1_column <- paste0(test_1, test_1_cutoff)
  
   for (test_6_cutoff in test_6_cutoffs) {
    comp3_column <- paste0(test_6, test_6_cutoff)
    
        # Create the combined column name
    combined_column <- paste0(comp1_column, "_", comp3_column)
    
    # Create values for the combined column where for each participant, the combined column value will be 1 if both column 1 AND column 2 have a value of 1
    screen_dataset2 <- screen_dataset2 %>% 
      mutate(!!combined_column := ifelse(get(comp1_column) == 1 & get(comp3_column) == 1, 1, 0))
    
    # While the previous code has been the same, the next 10 lines are for adding a third variable if interested in assessing the performance of three columns
     for (test_4_cutoff in test_4_cutoffs) {
    comp4_column <- paste0(test_4, test_4_cutoff)
    
        # Create the combined column name
    combined_column2 <- paste0(combined_column, "_", comp4_column)
    
    # Create the new column
    screen_dataset2 <- screen_dataset2 %>% 
      mutate(!!combined_column2 := ifelse(get(combined_column) == 1 & get(comp4_column) == 1, 1, 0))
    }
    
  
   }
  
  }
} 
# Change the columns that contain the associated test names (e.g, test_1 relating to "jorm") to factors. This allows for the variables to be used within the following below metric calculations
screen_dataset2 <- screen_dataset2 %>% 
  mutate_at(vars(contains(test_1)), as.factor) %>% 
  mutate_at(vars(contains(test_2)), as.factor) %>% 
  mutate_at(vars(contains(test_4)), as.factor) %>% 
  mutate_at(vars(contains(test_6)), as.factor) %>% 
  mutate_at(vars(contains(comparison_string)), as.factor)

```

```{r}
screen_dataset2 %>% 
  accuracy(cdr, jorm3.8_hmse25, case_weights = r1wtresp.x)

screen_dataset2 %>% 
  spec(cdr, jorm3.8_hmse25, case_weights = r1wtresp.x)

screen_dataset2 %>% 
  sens(cdr, jorm3.8_hmse25, case_weights = r1wtresp.x)
```



```{r}

# Select associated variables of interest and cut_off values. For example, if outcomes of interest were "jorm" with cut_off scores between 3 and 5, as well as "hmse" with cut_off values between 21 and 30, the below code will select all relevant columns. Reminder each "jorm" value will have a column for reach "hmse" value (e.g, jorm3_hmse21, jorm3_hmse22...., jorm3.1_hmse21 etc)
# Same code will be run if miss_hmse is ignore or false. If ignore it will be on the whole datset set
if (params$miss_hmse=="false"| params$miss_hmse=="ignore"){
screen_variables <- screen_dataset2 %>% 
  dplyr::select(jorm3_hmse21:jorm5_hmse30)
} else if (params$miss_hmse=="true")
# Same as the above code but exists to assess the performance of non_HMSE variables on participants with imputed HMSE data. 
  {
  screen_variables <- screen_dataset2 %>% 
    dplyr::select(jorm3_bl1_trav0:jorm5_bl12_trav1) %>% 
    dplyr::select(contains("trav"))
}
# Save extracted variables to a list
screen_list <- as.list(screen_variables)

# Instantiate an empty list
list_output <- list()

# Define the outcomes of interest
metric1 <- as.character("Accuracy")
metric2 <- as.character("Sensitivity")
metric3 <- as.character("Specificity")
metric4 <- as.character("AUC")
metric5 <- as.character("Distance")
metric6 <- as.character("Matthew_Class_Correlation")
metric7 <- as.character("Youdens_Index")
metric8 <- as.character("Neg Pred Value")
metric9 <- as.character("Pos Pred Value")

#Define gold standard variables

gold_std <- screen_dataset2$cdr
gold_std2 <- screen_dataset2$cdr_mci 



if (params$mci==FALSE) {
for(i in seq_along(screen_list)) {
  # Takes the ith name in screen_list and saves to variable name
    variable_name <- names(screen_list)[i]
    # Creates the confusion matrix comparing the ith outcome in screen_list compared to the defined gold standard and saves to x
   x <- caret::confusionMatrix(screen_list[[i]], 
                        gold_std,
                        positive = "1",
                        mode = "everything")
   # Calculates Youden's Index based on the calculated confusion matrix (x)
   y <- youden(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
   # Calculates the area under the curve for the ith outcome and gold standard
   auc <- pROC::auc(as.numeric(gold_std), as.numeric(screen_list[[i]]))
   # Calculates distance from upper left hand corner (where 0 is perfect) for the ith outcome compared to gold standard
   roc01 <- roc01(x$table[2,2], x$table[2,1], x$table[1,1], x$table[1, 2])
   # Calculates Matthew's Class Correlation between ith outcome of screen_list and gold standard
  # mcc <- mcc(gold_std, screen_list[[i]])

   # Save values to metric names
   values <- c(
     accuracy = x$overall[metric1],
     sensitivity = x$byClass[metric2],
     specificity = x$byClass[metric3],
     auc <- auc,
     distance <- roc01,
     #mcc <- mcc,
     youden = y,
     #neg_pred_value = x$byClass[metric8],
     #pos_pred_value = x$byClass[metric9],
     cut_off = variable_name
  )
   # Output values to the previously instantiated list
  list_output[[length(list_output) + 1]] <- values
}

} else {
  # This code is the same as above, but with mild cognitive impairment as the outcome rather than dementia
  for(i in seq_along(screen_list)){
    variable_name <- names(screen_list)[i]
   x <- caret::confusionMatrix(screen_list[[i]], 
                        gold_std2,
                        positive = "1",
                        mode = "everything")
   values <- c(
     accuracy = x$overall[metric1],
     sensitivity = x$byClass[metric2],
     specificity = x$byClass[metric3],
     neg_pred_value = x$byClass[metric8],
     #cut_off = screen_list[i][i]
     cut_off = variable_name
  )
   
  list_output[[length(list_output) + 1]] <- values
}
}
# Convert list_output of metric values to a data table
pop_table <- as_tibble(t(data.frame(list_output)))
# Change the names of the columns for the output tables to the previously defined metric names
new_names <- c(metric1,
               metric2,
               metric3,
               metric4,
               metric5,
               #metric6,
               metric7,
               #metric8,
               #metric9
               "cut_off")
#print(list_output)
names(pop_table)[1:7] <- new_names
```

``
